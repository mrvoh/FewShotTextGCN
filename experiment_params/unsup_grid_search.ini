[Main]
experiment_name=test_run_baseline
model_type= custom
debug=false
patience=500
num_seeds=5

[TextPreprocessor]
min_freq_word = 5
tokenizer_type = chinese
language = chinese
preprocess_type = textgcn
path_to_word2idx = word2idx.json
path_to_train_set = data/MLDoc/mldoc_chinese_train.tsv #data/unsup_dummy_data_train.tsv
path_to_test_set =  data/MLDoc/mldoc_chinese_test.tsv #data/unsup_dummy_data_test.tsv
percentage_dev = 0.98

[LitTextGNN]
lr = 0.01
optimizer_type=ranger

[LitSage]
use_unsup_loss=true
hidden_dim=64
dropout=0.0
num_layers=2
walks_per_node=5
walk_length=2
num_negative_samples=50
use_triplet_loss=true
triplet_margin=0.2
triplet_distance=cosine

[GraphSageTextDataset]
use_unsup_loss=true
batch_size = 16
num_neighbors_hop1 = 500
num_neighbors_hop2 = 20

[Trainer]
log_every_n_steps=1
gpus=1
max_epochs=1000